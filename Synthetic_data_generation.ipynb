{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53348929427849a699ab7f2c05bc39b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ccdba917eca4fa7af3b17e82513c0ca",
              "IPY_MODEL_1de5c4aab8ef4ef3b03a37fa3dc24e57",
              "IPY_MODEL_5e834d45dbcf4796ad0a7562de4defa0"
            ],
            "layout": "IPY_MODEL_aa33e63837ec4f3095c9717855f1e7e3"
          }
        },
        "6ccdba917eca4fa7af3b17e82513c0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_880aca2a3c004771940e747803b9f4b3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_028e61fffe734abebfbc3c0133619b3b",
            "value": "Generating‚Äá100k‚ÄáPairs:‚Äá100%"
          }
        },
        "1de5c4aab8ef4ef3b03a37fa3dc24e57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c9c4d5cafc546cfaa9afdc867ca7213",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ab999fae7c24af4a9922530d740c71c",
            "value": 100000
          }
        },
        "5e834d45dbcf4796ad0a7562de4defa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82322995bcff440e9664f7ad72f1cb4e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_413780a33f7a4a6d81ebe2a3acc1219a",
            "value": "‚Äá100000/100000‚Äá[00:28&lt;00:00,‚Äá3711.19it/s]"
          }
        },
        "aa33e63837ec4f3095c9717855f1e7e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "880aca2a3c004771940e747803b9f4b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "028e61fffe734abebfbc3c0133619b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c9c4d5cafc546cfaa9afdc867ca7213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ab999fae7c24af4a9922530d740c71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82322995bcff440e9664f7ad72f1cb4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413780a33f7a4a6d81ebe2a3acc1219a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkiFwiWWp34T",
        "outputId": "98d81c86-a771-427e-e3d2-680cc2e5bb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Step 1: Generating 50k Voice and 50k Gait Datasets ===\n",
            "Data will be saved to: /content/drive/MyDrive/Parkinsons_Research_Project/data/generated_50k\n",
            "\n",
            "üé§ Generating 50000 realistic voice samples...\n",
            "‚úÖ Generated voice data: (50000, 14)\n",
            "‚úÖ Voice dataset (50,000 samples) saved to: /content/drive/MyDrive/Parkinsons_Research_Project/data/generated_50k/synthetic_voice_data_50k.csv\n",
            "   Voice class distribution: \n",
            "true_label\n",
            "0    25000\n",
            "1    25000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "üö∂ Generating 50000 realistic gait subjects...\n",
            "‚úÖ Generated gait data: (50000, 19)\n",
            "‚úÖ Gait dataset (50,000 samples) saved to: /content/drive/MyDrive/Parkinsons_Research_Project/data/generated_50k/synthetic_gait_data_50k.csv\n",
            "   Gait class distribution: \n",
            "true_label\n",
            "0    25000\n",
            "1    25000\n",
            "Name: count, dtype: int64\n",
            "\n",
            "--- Step 1 Complete ---\n",
            "You now have two separate, balanced 50k-sample CSV files in your Google Drive.\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Generate and Save 50k Voice and 50k Gait Datasets\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "\n",
        "print(\"=== Step 1: Generating 50k Voice and 50k Gait Datasets ===\")\n",
        "\n",
        "# --- 1. Define Project Paths ---\n",
        "project_root = \"/content/drive/MyDrive/Parkinsons_Research_Project\"\n",
        "# We will save these large datasets in a new, specific folder\n",
        "data_save_dir = os.path.join(project_root, \"data\", \"generated_50k\")\n",
        "os.makedirs(data_save_dir, exist_ok=True)\n",
        "print(f\"Data will be saved to: {data_save_dir}\")\n",
        "\n",
        "# --- 2. Define the Data Generator Class ---\n",
        "class UltraRealisticDataGenerator:\n",
        "    \"\"\"Creates a challenging dataset with substantial class overlap.\"\"\"\n",
        "\n",
        "    def __init__(self, random_state=42):\n",
        "        self.random_state = random_state\n",
        "        np.random.seed(random_state)\n",
        "        # Define feature lists\n",
        "        self.voice_features = ['Jitter(%)', 'Jitter(Abs)', 'Jitter:RAP', 'Jitter:PPQ5', 'Shimmer',\n",
        "                               'Shimmer(dB)', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']\n",
        "        self.gait_features = ['stride_time_mean', 'stride_time_std', 'step_time_mean', 'step_time_std',\n",
        "                              'cadence', 'velocity', 'step_length', 'stride_length', 'force_asymmetry',\n",
        "                              'step_time_cv', 'stride_time_cv', 'left_force_mean', 'right_force_mean',\n",
        "                              'left_force_std', 'right_force_std', 'swing_time_ratio', 'stance_time_ratio']\n",
        "\n",
        "    def generate_ultra_realistic_voice_data(self, n_controls=2500, n_parkinsons=2500, n_recordings=10):\n",
        "        print(f\"\\nüé§ Generating {n_controls * n_recordings + n_parkinsons * n_recordings} realistic voice samples...\")\n",
        "        n_subjects = n_controls + n_parkinsons\n",
        "\n",
        "        # MAJOR OVERLAP parameters\n",
        "        voice_params = {\n",
        "            'Jitter(%)': (1.0, 0.6), 'Jitter(Abs)': (0.0001, 0.00005), 'Jitter:RAP': (0.7, 0.4),\n",
        "            'Jitter:PPQ5': (0.75, 0.45), 'Shimmer': (4.5, 2.0), 'Shimmer(dB)': (0.35, 0.15),\n",
        "            'NHR': (0.13, 0.08), 'HNR': (19, 6), 'RPDE': (0.55, 0.2),\n",
        "            'DFA': (0.63, 0.18), 'PPE': (0.16, 0.08)\n",
        "        }\n",
        "\n",
        "        voice_data = []\n",
        "        for subject_id in range(1, n_subjects + 1):\n",
        "            is_parkinson = 1 if subject_id > n_controls else 0\n",
        "            for recording_id in range(1, n_recordings + 1):\n",
        "                subject_data = {\n",
        "                    'subject#': subject_id,\n",
        "                    'recording_id': recording_id,\n",
        "                    'true_label': is_parkinson\n",
        "                }\n",
        "                for feature in self.voice_features:\n",
        "                    shared_mean, shared_std = voice_params[feature]\n",
        "                    base_value = np.random.normal(shared_mean, shared_std * 1.8)\n",
        "                    class_bias = np.random.normal(0.1, 0.05) if is_parkinson else np.random.normal(-0.1, 0.05)\n",
        "                    adjusted_value = max(0, base_value * (1 + class_bias * 0.1))\n",
        "                    subject_data[feature] = adjusted_value\n",
        "                voice_data.append(subject_data)\n",
        "\n",
        "        voice_df = pd.DataFrame(voice_data)\n",
        "        print(f\"‚úÖ Generated voice data: {voice_df.shape}\")\n",
        "        return voice_df\n",
        "\n",
        "    def generate_ultra_realistic_gait_data(self, n_controls=25000, n_parkinsons=25000):\n",
        "        print(f\"\\nüö∂ Generating {n_controls + n_parkinsons} realistic gait subjects...\")\n",
        "        n_subjects = n_controls + n_parkinsons\n",
        "\n",
        "        # MAJOR overlap parameters\n",
        "        gait_params = {\n",
        "            'stride_time_mean': (1.2, 0.15), 'stride_time_std': (0.10, 0.04), 'step_time_mean': (0.6, 0.08),\n",
        "            'step_time_std': (0.06, 0.03), 'cadence': (105, 12), 'velocity': (1.05, 0.3),\n",
        "            'step_length': (0.58, 0.12), 'stride_length': (1.15, 0.22), 'force_asymmetry': (30, 20),\n",
        "            'step_time_cv': (0.10, 0.04), 'stride_time_cv': (0.08, 0.04), 'left_force_mean': (425, 80),\n",
        "            'right_force_mean': (420, 85), 'left_force_std': (110, 35), 'right_force_std': (115, 38),\n",
        "            'swing_time_ratio': (0.39, 0.05), 'stance_time_ratio': (0.61, 0.05)\n",
        "        }\n",
        "\n",
        "        gait_data = []\n",
        "        for i in range(n_subjects):\n",
        "            is_parkinson = 1 if i >= n_controls else 0\n",
        "            subject_data = {\n",
        "                'subject_id': f\"Sub_{i+1:05d}\",\n",
        "                'true_label': is_parkinson\n",
        "            }\n",
        "            for feature in self.gait_features:\n",
        "                shared_mean, shared_std = gait_params[feature]\n",
        "                base_value = np.random.normal(shared_mean, shared_std * 1.5)\n",
        "                class_bias = np.random.normal(0.08, 0.03) if is_parkinson else np.random.normal(-0.08, 0.03)\n",
        "                adjusted_value = max(0, base_value * (1 + class_bias * 0.05))\n",
        "                subject_data[feature] = adjusted_value\n",
        "            gait_data.append(subject_data)\n",
        "\n",
        "        gait_df = pd.DataFrame(gait_data)\n",
        "        print(f\"‚úÖ Generated gait data: {gait_df.shape}\")\n",
        "        return gait_df\n",
        "\n",
        "# --- 3. Execute Generation and Save Files ---\n",
        "\n",
        "# Instantiate the generator\n",
        "data_generator_50k = UltraRealisticDataGenerator()\n",
        "\n",
        "# --- Generate and Save VOICE Data ---\n",
        "# We generate 5,000 subjects (2500/2500) with 10 recordings each = 50,000 samples\n",
        "try:\n",
        "    voice_df_50k = data_generator_50k.generate_ultra_realistic_voice_data(\n",
        "        n_controls=2500, n_parkinsons=2500, n_recordings=10\n",
        "    )\n",
        "    voice_save_path = os.path.join(data_save_dir, \"synthetic_voice_data_50k.csv\")\n",
        "    voice_df_50k.to_csv(voice_save_path, index=False)\n",
        "    print(f\"‚úÖ Voice dataset (50,000 samples) saved to: {voice_save_path}\")\n",
        "    # Verify\n",
        "    print(f\"   Voice class distribution: \\n{voice_df_50k['true_label'].value_counts()}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error generating or saving voice data: {e}\")\n",
        "\n",
        "# --- Generate and Save GAIT Data ---\n",
        "# We generate 50,000 subjects (25000/25000) with 1 recording each = 50,000 samples\n",
        "try:\n",
        "    gait_df_50k = data_generator_50k.generate_ultra_realistic_gait_data(\n",
        "        n_controls=25000, n_parkinsons=25000\n",
        "    )\n",
        "    gait_save_path = os.path.join(data_save_dir, \"synthetic_gait_data_50k.csv\")\n",
        "    gait_df_50k.to_csv(gait_save_path, index=False)\n",
        "    print(f\"‚úÖ Gait dataset (50,000 samples) saved to: {gait_save_path}\")\n",
        "    # Verify\n",
        "    print(f\"   Gait class distribution: \\n{gait_df_50k['true_label'].value_counts()}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error generating or saving gait data: {e}\")\n",
        "\n",
        "print(\"\\n--- Step 1 Complete ---\")\n",
        "print(\"You now have two separate, balanced 50k-sample CSV files in your Google Drive.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Create 100k Federated Dataset & Save\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import os\n",
        "import sys\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm.notebook import tqdm # Import tqdm for a progress bar\n",
        "\n",
        "print(\"=== Step 3: Creating 100k Federated Dataset ===\")\n",
        "\n",
        "# --- 1. Define Paths ---\n",
        "project_root = \"/content/drive/MyDrive/Parkinsons_Research_Project\"\n",
        "data_load_dir = os.path.join(project_root, \"data\", \"generated_50k\") # Load 50k CSVs\n",
        "# Define a new directory for this 100k dataset\n",
        "data_save_dir = os.path.join(project_root, \"data\", \"federated_100k\")\n",
        "os.makedirs(data_save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Loading raw 50k data from: {data_load_dir}\")\n",
        "print(f\"Final 100k federated dataset will be saved to: {data_save_dir}\")\n",
        "\n",
        "# --- 2. Load Raw Data ---\n",
        "try:\n",
        "    voice_df_50k = pd.read_csv(os.path.join(data_load_dir, \"synthetic_voice_data_50k.csv\"))\n",
        "    gait_df_50k = pd.read_csv(os.path.join(data_load_dir, \"synthetic_gait_data_50k.csv\"))\n",
        "    print(f\"‚úÖ Loaded 50k voice data: {voice_df_50k.shape}\")\n",
        "    print(f\"‚úÖ Loaded 50k gait data: {gait_df_50k.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"‚ùå Error: Raw 50k CSV files not found. Please re-run Step 1.\")\n",
        "    raise SystemExit(\"Data loading failed.\")\n",
        "\n",
        "# --- 3. Define Feature Lists ---\n",
        "voice_features = ['Jitter(%)', 'Jitter(Abs)', 'Jitter:RAP', 'Jitter:PPQ5', 'Shimmer',\n",
        "                  'Shimmer(dB)', 'NHR', 'HNR', 'RPDE', 'DFA', 'PPE']\n",
        "gait_features = ['stride_time_mean', 'stride_time_std', 'step_time_mean', 'step_time_std',\n",
        "                 'cadence', 'velocity', 'step_length', 'stride_length', 'force_asymmetry',\n",
        "                 'step_time_cv', 'stride_time_cv', 'left_force_mean', 'right_force_mean',\n",
        "                 'left_force_std', 'right_force_std', 'swing_time_ratio', 'stance_time_ratio']\n",
        "\n",
        "# --- 4. Process and Scale Voice Data (5,000 subjects) ---\n",
        "print(\"\\n--- Processing Voice Data ---\")\n",
        "subject_voice = voice_df_50k.groupby('subject#')[voice_features].mean().reset_index()\n",
        "subject_voice_labels = voice_df_50k.groupby('subject#')['true_label'].first().values\n",
        "subject_voice['true_label'] = subject_voice_labels\n",
        "print(f\"Aggregated voice data to {subject_voice.shape} subjects (2.5k C, 2.5k P)\")\n",
        "voice_scaler = StandardScaler()\n",
        "voice_scaled = voice_scaler.fit_transform(subject_voice[voice_features])\n",
        "print(\"Voice features scaled.\")\n",
        "\n",
        "# --- 5. Process and Scale Gait Data (50,000 subjects) ---\n",
        "print(\"\\n--- Processing Gait Data ---\")\n",
        "gait_processed = gait_df_50k.copy()\n",
        "gait_processed['true_label'] = gait_df_50k['true_label']\n",
        "gait_scaler = StandardScaler()\n",
        "gait_scaled = gait_scaler.fit_transform(gait_processed[gait_features])\n",
        "print(\"Gait features scaled.\")\n",
        "\n",
        "# --- 6. Create Federated Pairs (100k pairs) ---\n",
        "n_pairs = 100000 # <-- This is our new target\n",
        "label_noise = 0.20 # 20% label noise\n",
        "feature_noise = 0.12 # 12% feature noise\n",
        "np.random.seed(42)\n",
        "\n",
        "multimodal_data = []\n",
        "multimodal_labels = []\n",
        "pair_info = []\n",
        "print(f\"\\n--- Creating {n_pairs} Federated Pairs (with {label_noise*100:.0f}% label noise) ---\")\n",
        "\n",
        "# Pre-filter gait data for efficiency\n",
        "gait_controls = gait_scaled[gait_processed['true_label'] == 0]\n",
        "gait_parkinsons = gait_scaled[gait_processed['true_label'] == 1]\n",
        "gait_controls_info = gait_processed[gait_processed['true_label'] == 0]\n",
        "gait_parkinsons_info = gait_processed[gait_processed['true_label'] == 1]\n",
        "n_voice_subjects = len(subject_voice)\n",
        "\n",
        "# Use tqdm for a progress bar, as this will take some time\n",
        "for i in tqdm(range(n_pairs), desc=\"Generating 100k Pairs\"):\n",
        "    # We re-use the 5,000 voice subjects by looping over them\n",
        "    voice_idx = i % n_voice_subjects\n",
        "\n",
        "    voice_label = subject_voice.iloc[voice_idx]['true_label']\n",
        "    voice_data_scaled = voice_scaled[voice_idx]\n",
        "\n",
        "    if np.random.random() < label_noise:\n",
        "        # Mismatched pair\n",
        "        pair_type = \"MISMATCHED\"\n",
        "        if voice_label == 0: # Voice is Control, pair with PD Gait\n",
        "            gait_idx = np.random.randint(len(gait_parkinsons))\n",
        "            gait_data_scaled = gait_parkinsons[gait_idx]\n",
        "            gait_info_row = gait_parkinsons_info.iloc[gait_idx]\n",
        "        else: # Voice is PD, pair with Control Gait\n",
        "            gait_idx = np.random.randint(len(gait_controls))\n",
        "            gait_data_scaled = gait_controls[gait_idx]\n",
        "            gait_info_row = gait_controls_info.iloc[gait_idx]\n",
        "    else:\n",
        "        # Matched pair\n",
        "        pair_type = \"MATCHED\"\n",
        "        if voice_label == 0: # Voice is Control, pair with Control Gait\n",
        "            gait_idx = np.random.randint(len(gait_controls))\n",
        "            gait_data_scaled = gait_controls[gait_idx]\n",
        "            gait_info_row = gait_controls_info.iloc[gait_idx]\n",
        "        else: # Voice is PD, pair with PD Gait\n",
        "            gait_idx = np.random.randint(len(gait_parkinsons))\n",
        "            gait_data_scaled = gait_parkinsons[gait_idx]\n",
        "            gait_info_row = gait_parkinsons_info.iloc[gait_idx]\n",
        "\n",
        "    # Add feature noise\n",
        "    voice_noisy = voice_data_scaled + np.random.normal(0, feature_noise, voice_data_scaled.shape)\n",
        "    gait_noisy = gait_data_scaled + np.random.normal(0, feature_noise, gait_data_scaled.shape)\n",
        "\n",
        "    combined_features = np.concatenate([voice_noisy, gait_noisy])\n",
        "    multimodal_data.append(combined_features)\n",
        "    multimodal_labels.append(voice_label) # Use voice label as ground truth\n",
        "\n",
        "    pair_info.append({\n",
        "        'pair_id': i,\n",
        "        'voice_subject': subject_voice.iloc[voice_idx]['subject#'],\n",
        "        'voice_label': int(voice_label),\n",
        "        'gait_subject_id': gait_info_row['subject_id'],\n",
        "        'gait_label': int(gait_info_row['true_label']),\n",
        "        'pair_type': pair_type,\n",
        "        'label_match': int(voice_label == gait_info_row['true_label'])\n",
        "    })\n",
        "\n",
        "X_federated_100k = np.array(multimodal_data)\n",
        "y_federated_100k = np.array(multimodal_labels)\n",
        "pair_info_100k = pd.DataFrame(pair_info)\n",
        "\n",
        "print(f\"\\n‚úÖ Final Federated Dataset Created:\")\n",
        "print(f\"    X Shape: {X_federated_100k.shape}\")\n",
        "print(f\"    y Shape: {y_federated_100k.shape}\")\n",
        "print(f\"    Class Distribution: {dict(zip(*np.unique(y_federated_100k, return_counts=True)))}\")\n",
        "print(f\"    Label Match Rate: {pair_info_100k['label_match'].mean():.3f}\")\n",
        "\n",
        "# --- 7. Save Final Federated Dataset and Scalers ---\n",
        "print(f\"\\n--- Saving Federated 100k Dataset Files to {data_save_dir} ---\")\n",
        "try:\n",
        "    np.save(os.path.join(data_save_dir, 'X_federated_100k.npy'), X_federated_100k)\n",
        "    np.save(os.path.join(data_save_dir, 'y_federated_100k.npy'), y_federated_100k)\n",
        "    pair_info_100k.to_csv(os.path.join(data_save_dir, 'pair_info_100k.csv'), index=False)\n",
        "\n",
        "    # We save the scalers that were fit on the source data\n",
        "    joblib.dump(voice_scaler, os.path.join(data_save_dir, 'voice_scaler.pkl'))\n",
        "    joblib.dump(gait_scaler, os.path.join(data_save_dir, 'gait_scaler.pkl'))\n",
        "\n",
        "    # Save feature lists\n",
        "    with open(os.path.join(data_save_dir, 'voice_features.txt'), 'w') as f: f.write('\\n'.join(voice_features))\n",
        "    with open(os.path.join(data_save_dir, 'gait_features.txt'), 'w') as f: f.write('\\n'.join(gait_features))\n",
        "\n",
        "    print(\"‚úÖ All federated 100k data files saved successfully.\")\n",
        "    print(\"   Ready for next steps (Baseline Evaluation and CM-DAN Training).\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error saving 100k federated data: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465,
          "referenced_widgets": [
            "53348929427849a699ab7f2c05bc39b6",
            "6ccdba917eca4fa7af3b17e82513c0ca",
            "1de5c4aab8ef4ef3b03a37fa3dc24e57",
            "5e834d45dbcf4796ad0a7562de4defa0",
            "aa33e63837ec4f3095c9717855f1e7e3",
            "880aca2a3c004771940e747803b9f4b3",
            "028e61fffe734abebfbc3c0133619b3b",
            "2c9c4d5cafc546cfaa9afdc867ca7213",
            "4ab999fae7c24af4a9922530d740c71c",
            "82322995bcff440e9664f7ad72f1cb4e",
            "413780a33f7a4a6d81ebe2a3acc1219a"
          ]
        },
        "id": "zfC-H2NKr4bb",
        "outputId": "f6431786-f531-42a5-8266-6d274461bf4f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Step 3: Creating 100k Federated Dataset ===\n",
            "Loading raw 50k data from: /content/drive/MyDrive/Parkinsons_Research_Project/data/generated_50k\n",
            "Final 100k federated dataset will be saved to: /content/drive/MyDrive/Parkinsons_Research_Project/data/federated_100k\n",
            "‚úÖ Loaded 50k voice data: (50000, 14)\n",
            "‚úÖ Loaded 50k gait data: (50000, 19)\n",
            "\n",
            "--- Processing Voice Data ---\n",
            "Aggregated voice data to (5000, 13) subjects (2.5k C, 2.5k P)\n",
            "Voice features scaled.\n",
            "\n",
            "--- Processing Gait Data ---\n",
            "Gait features scaled.\n",
            "\n",
            "--- Creating 100000 Federated Pairs (with 20% label noise) ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating 100k Pairs:   0%|          | 0/100000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53348929427849a699ab7f2c05bc39b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Final Federated Dataset Created:\n",
            "    X Shape: (100000, 28)\n",
            "    y Shape: (100000,)\n",
            "    Class Distribution: {np.float64(0.0): np.int64(50000), np.float64(1.0): np.int64(50000)}\n",
            "    Label Match Rate: 0.802\n",
            "\n",
            "--- Saving Federated 100k Dataset Files to /content/drive/MyDrive/Parkinsons_Research_Project/data/federated_100k ---\n",
            "‚úÖ All federated 100k data files saved successfully.\n",
            "   Ready for next steps (Baseline Evaluation and CM-DAN Training).\n"
          ]
        }
      ]
    }
  ]
}